llm:
  provider: ollama
  model: llama3
  base_url: http://localhost:11434/v1
  temperature: 0.7
